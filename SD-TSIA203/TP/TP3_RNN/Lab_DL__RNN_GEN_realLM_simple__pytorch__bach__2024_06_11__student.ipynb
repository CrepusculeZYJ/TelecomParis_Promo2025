{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPOXHysXKGLW"
      },
      "source": [
        "# Lab Deep Learning/ Recurrent Neural Networks/ in pytorch\n",
        "\n",
        "## Training language model for generating sequences (One-to-Many)\n",
        "\n",
        "**Author: geoffroy.peeters@telecom-paris.fr**\n",
        "\n",
        "**Version**: 2024/06/11 (changed to pytorch, changed almost everything)\n",
        "\n",
        "For any remark or suggestion, please feel free to contact me.\n",
        "\n",
        "\n",
        "## Objective:\n",
        "\n",
        "- We will train a network to learn a language model and then use it to generate new sequences.\n",
        "\n",
        "- Instead of training the language model on text-documents (as it is the case in most examples) we will train it to learn the language of the music of [Johann_Sebastian_Bach](https://en.wikipedia.org/wiki/Johann_Sebastian_Bach).\n",
        "For this, we will learn how J. S. Bach's \"Cello suite\" have been composed.\n",
        "Here is an example of a \"Cello suite\" [Link](https://www.youtube.com/watch?v=mGQLXRTl3Z0).\n",
        "\n",
        "- Rather than analyzing the audio signal, we use a symbolic representation of the \"Cello suite\" through their [MIDI files](https://en.wikipedia.org/wiki/MIDI#MIDI_files).\n",
        "  - A MIDI file encodes in a file, the set of musical notes, their duration, and intensity which have to be played by each instrument to \"render\" a musical piece. The \"rendering\" is usually operated by a MIDI synthesizer (such as VLC, QuickTime) or a real performer (a musician reading a score).\n",
        "\n",
        "- We will first train a language model on the whole set of MIDI files of the \"Cello suites\".\n",
        "- We will then sample this language model to create a new MIDI file which will be a brand new \"Cello suite\" composed by the computer.\n",
        "\n",
        "### Questions:\n",
        "\n",
        "In the bottom part of this lab, you will have to answer a set of questions. Answers to those only necessitates a couple of sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjlvVXvgbpbW"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plK5POiPDUqT",
        "outputId": "71fe434d-92ef-457a-8506-fb5986ed324e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pretty_midi\n",
            "  Using cached pretty_midi-0.2.10-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.7.0 in c:\\users\\gaalok\\desktop\\telecomparis_promo2025\\sd-tsia203\\tp\\tp3_rnn\\.conda\\lib\\site-packages (from pretty_midi) (2.0.1)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Using cached mido-1.3.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six in c:\\users\\gaalok\\desktop\\telecomparis_promo2025\\sd-tsia203\\tp\\tp3_rnn\\.conda\\lib\\site-packages (from pretty_midi) (1.16.0)\n",
            "Collecting packaging~=23.1 (from mido>=1.1.16->pretty_midi)\n",
            "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Using cached mido-1.3.2-py3-none-any.whl (54 kB)\n",
            "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
            "Installing collected packages: packaging, mido, pretty_midi\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "Successfully installed mido-1.3.2 packaging-23.2 pretty_midi-0.2.10\n"
          ]
        }
      ],
      "source": [
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IXocQU0HDntL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pretty_midi\n",
        "from scipy.io import wavfile\n",
        "import IPython\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob\n",
        "from argparse import Namespace\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "student = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6YQL6s5j93E"
      },
      "source": [
        "## Parameters of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gZx9igIOvtU"
      },
      "outputs": [],
      "source": [
        "param = Namespace()\n",
        "\n",
        "param.n_x = 79 # --- input dimension of x<t>, number of musical-pitch considered\n",
        "param.max_midi_T_x = 1000 # --- maximum considered length of each bach suite\n",
        "param.model_T_x = 100 # --- considered duration T_x of sequence for training and generation\n",
        "param.model_n_a = 32 # --- hidden dimension of LSTM\n",
        "\n",
        "param.dropout_rate = 0.3\n",
        "param.batch_size = 64\n",
        "param.n_epoch = 1000\n",
        "\n",
        "param.model_T_generate = 100 # --- number of time steps to generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgG1EmxKDhE5"
      },
      "source": [
        "# Get the data\n",
        "\n",
        "## Collect data to create the language model\n",
        "\n",
        "We download the 36 MIDI files corresponding to the 36 \"Cello suites\" composed by J. S. Bach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTveLq9Mnh-M",
        "outputId": "77f082e4-9fec-450c-e4d4-5a550f3d0c39"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve('https://drive.google.com/uc?export=download&id=1FzNBMlhSYdefQUHpfRykY05CsYkuI2Ez', 'Archive.zip');\n",
        "import shutil\n",
        "shutil.unpack_archive('Archive.zip', './', 'zip')\n",
        "\n",
        "DIR = './'\n",
        "midi_file_l = glob.glob(DIR + 'cs*.mid')\n",
        "print(midi_file_l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9Tgx3ooDgSP"
      },
      "outputs": [],
      "source": [
        "#DIR = './'\n",
        "#import urllib.request\n",
        "#midi_file_l = ['cs1-2all.mid', 'cs5-1pre.mid', 'cs4-1pre.mid', 'cs3-5bou.mid', 'cs1-4sar.mid', 'cs2-5men.mid', 'cs3-3cou.mid', 'cs2-3cou.mid', 'cs1-6gig.mid', 'cs6-4sar.mid', 'cs4-5bou.mid', 'cs4-3cou.mid', 'cs5-3cou.mid', 'cs6-5gav.mid', 'cs6-6gig.mid', 'cs6-2all.mid', 'cs2-1pre.mid', 'cs3-1pre.mid', 'cs3-6gig.mid', 'cs2-6gig.mid', 'cs2-4sar.mid', 'cs3-4sar.mid', 'cs1-5men.mid', 'cs1-3cou.mid', 'cs6-1pre.mid', 'cs2-2all.mid', 'cs3-2all.mid', 'cs1-1pre.mid', 'cs5-2all.mid', 'cs4-2all.mid', 'cs5-5gav.mid', 'cs4-6gig.mid', 'cs5-6gig.mid', 'cs5-4sar.mid', 'cs4-4sar.mid', 'cs6-3cou.mid']\n",
        "#for midi_file in midi_file_l:\n",
        "#    #if os.path.isfile(DIR + midi_file) is None:\n",
        "#    urllib.request.urlretrieve (\"http://www.jsbach.net/midi/\" + midi_file, DIR + midi_file)\n",
        "\n",
        "#midi_file_l = glob.glob(DIR + 'cs*.mid')\n",
        "#print(midi_file_l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgCE_6urcVsj"
      },
      "source": [
        "## Read and convert all MIDI files\n",
        "\n",
        "We illustrate here the content of a MIDI file. Each file contains a list of notes to be played over time. Each note is characterized by\n",
        "- its `pitch` (in MIDI note number, la3=A4=69)\n",
        "- its `start` time (when to start playing the note)\n",
        "- its `stop` time (when to stop playing the note)\n",
        "- its `duration` (which is computed as stop-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEg5c8wfj93K",
        "outputId": "d59791fe-73b7-4c32-9959-4cf01520610f"
      },
      "outputs": [],
      "source": [
        "# --- Read a single MIDI file\n",
        "midi_data = pretty_midi.PrettyMIDI(midi_file_l[0])\n",
        "# --- Display the note pitch, start, end and duration\n",
        "for note in midi_data.instruments[0].notes[:10]:\n",
        "    print('pitch: %d, start: %f, end: %f, duration: %f' % (note.pitch, note.start, note.end, note.end-note.start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDofyEKjcd4E"
      },
      "source": [
        "For each MIDI file,\n",
        "- we read it\n",
        "- we only retain the `pitch` information (we name it `note`) .\n",
        "- we convert this list of notes (`note_l`)  to a one-hot-encoding matrix `X_ohe` of dimensions `(midi_T_x, param.n_x)` where `param.n_x` is the number of possible musical notes.\n",
        "\n",
        "Remark: the length of the sequences `midi_T_x` can vary from one sequence to the other but is truncated to `param.max_midi_T_x`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EirVcbKxEe-3"
      },
      "outputs": [],
      "source": [
        "def F_convert_midi_2_list(midi_file_l, n_x, max_midi_T_x):\n",
        "    \"\"\"\n",
        "    read the notes within all midi files\n",
        "    truncate the length if > max_midi_T_x\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    midi_file_l:\n",
        "        list of MIDI files\n",
        "    n_x:\n",
        "        dimension of the one-hot-encoding\n",
        "    max_midi_T_x:\n",
        "        the maximum number of notes we read in a given midi_file\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_list:\n",
        "        a list of np.array X_ohe of size (midi_T_x, n_x) which contains the one-hot-encoding representation of notes over time\n",
        "    \"\"\"\n",
        "    X_list = []\n",
        "\n",
        "    for midi_file in midi_file_l:\n",
        "        # --- read the MIDI file\n",
        "        midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
        "        note_l = [note.pitch for note in midi_data.instruments[0].notes]\n",
        "        midi_T_x = len(note_l) if len(note_l) < max_midi_T_x else max_midi_T_x\n",
        "        # --- convert to one-hot-encoding\n",
        "        if student:\n",
        "            # --- START CODE HERE (01)\n",
        "            X_ohe = np.zeros((midi_T_x, n_x))\n",
        "            for i in range(midi_T_x):\n",
        "                X_ohe[i, note_l[i]-1] = 1\n",
        "            # --- END CODE HERE\n",
        "        # --- add X_ohe to the list X_list\n",
        "        X_list.append(X_ohe)\n",
        "\n",
        "    return X_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY9io0K0V0SG",
        "outputId": "0d314489-1536-4074-eb00-b738a49c14a4"
      },
      "outputs": [],
      "source": [
        "X_list = F_convert_midi_2_list(midi_file_l, param.n_x, param.max_midi_T_x)\n",
        "print(len(X_list))\n",
        "print(X_list[0].shape)\n",
        "print(X_list[1].shape)\n",
        "print(X_list[2].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSf8RDL5cv7V"
      },
      "source": [
        "## Display the set of notes over time for a specific track"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "wesPFMZHcvKG",
        "outputId": "4a0f79e1-31fb-4d0e-824b-5e5c7cf1a84f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.imshow(X_list[2].T, aspect='auto')\n",
        "plt.set_cmap('gray_r')\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMHtioR_c5y3"
      },
      "source": [
        "## Data conversion for the training of language model\n",
        "\n",
        "We want to train a language model, i.e. a model thats predict a note given past notes: $p(x^{<\\tau>} | x^{<1>}, x^{<2>}, ... x^{<\\tau-1>})$.\n",
        "\n",
        "A simple way to do this is to create (for each MIDI sequence and for each possible starting note `t` within this MIDI sequence) two sequences:\n",
        "- an input sequence $\\{x\\}$:\n",
        "  - which contains a sub-sequence of length `param.model_T_x`;  this sub-sequence range from `t` to `t+param.model_T_x-1`\n",
        "- an output sequence $\\{y\\}$ :\n",
        "  - which contains the same sub-sequence but delayed by one time step: ranging from `t+1` to `t+param.model_T_x`\n",
        "\n",
        "<img src=\"https://perso.telecom-paristech.fr/gpeeters/doc/Lab_DL_RNN_03.png\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGzvp4RCC0XX"
      },
      "outputs": [],
      "source": [
        "def F_convert_list_2_data(X_list, model_T_x, sequence_step=1):\n",
        "    \"\"\"\n",
        "    convert X_list to input X_train and output Y_train training data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_list:\n",
        "        a list of np.array X_ohe of size (midi_T_x, n_x) which contains the one-hot-encoding representation of notes over time\n",
        "    model_T_x:\n",
        "        the length of the input and output sequences\n",
        "    sequence_step:\n",
        "        the advancement step between successive sequences\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_train:\n",
        "        the set of all m input sequences; np.array of shape (m, model_T_x, n_x)\n",
        "    Y_train:\n",
        "        the set of all m output sequences; np.array of shape (m, model_T_x, n_x)\n",
        "\n",
        "            note:   m is the total number of training items,\n",
        "                    it is be larger than the number of MIDI files since we use several starting time t in each MIDI file\n",
        "    \"\"\"\n",
        "\n",
        "    if student:\n",
        "        # --- START CODE HERE (02)\n",
        "        X_train_list = []\n",
        "        Y_train_list = []\n",
        "        for X_ohe in X_list:\n",
        "            for t in range(0, len(X_ohe) - model_T_x, sequence_step):\n",
        "                X_train_list.append(X_ohe[t:t + model_T_x])\n",
        "                Y_train_list.append(X_ohe[t + 1:t + model_T_x + 1])\n",
        "\n",
        "        # --- END CODE HERE\n",
        "\n",
        "    X_train = np.asarray(X_train_list)\n",
        "    Y_train = np.asarray(Y_train_list)\n",
        "\n",
        "    return X_train, Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "nfHmJ3GQV0SH",
        "outputId": "0da8c8b2-b709-48be-af94-c768ce27557d"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = F_convert_list_2_data(X_list, param.model_T_x)\n",
        "# --- X_train is of shape (m, model_T_x, n_x)\n",
        "print(\"X_train.shape:\", X_train.shape)\n",
        "# --- Y_train is of shape (m, model_T_x, n_x)\n",
        "print(\"Y_train.shape:\", Y_train.shape)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1,2,1); plt.imshow(X_train[20,:,:].T, aspect='auto'); plt.grid(True); plt.title('X_train')\n",
        "plt.subplot(1,2,2); plt.imshow(Y_train[20,:,:].T, aspect='auto'); plt.grid(True); plt.title('Y_train')\n",
        "plt.set_cmap('gray_r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhNPrmvveuH3"
      },
      "source": [
        "# Training the language model\n",
        "\n",
        "## Creating the model\n",
        "To learn the language model we will train an RNN with input `X_train` and output `Y_train`.  \n",
        "For each example, we give to the network a sequence of notes from `t` to `t+param.model_T_x-1`  and ask the network to predict the following note of each sequence `t+1` to `t+param.model_T_x`.\n",
        "We already created those in `X_train` and `Y_train`.\n",
        "\n",
        "The network architecture is the following:\n",
        "- (1a) a layer of `LSTM` with `param.model_n_a` units\n",
        "- (1b) a layer of DropOut with rate `param.dropout_rate` (which is the probability to \"drop-out\" one neuron)\n",
        "\n",
        "- (2a) a layer of `LSTM` with `param.model_n_a` units\n",
        "- (2b) a layer of DropOut with rate `param.dropout_rate` (which is the probability to \"drop-out\" one neuron)\n",
        "\n",
        "- (3) a layer of `LSTM` with `param.model_n_a` units\n",
        "\n",
        "- (4a) a `Linear` layer projecting to `model_n_a` neurons with a `tanh` activation\n",
        "- (4b) a layer of DropOut with rate `param.dropout_rate` (which is the probability to \"drop-out\" one neuron)\n",
        "\n",
        "- (5) a `Linear` layer projecting to `n_x` neurons\n",
        "\n",
        "Note that the last `softmax` activation (which predict the probability of each of the $n_x$ notes as output) is not included in the model but will be included directly in the Loss.\n",
        "\n",
        "Note that the `.forward` method\n",
        "- also takes as **input** the previous RNN values $s^{(t-1)}$. The previous RNN value sums up the times $x^{(1)} ... x^{(t-1)}$.\n",
        "In the case of LSTM, $s^{(t-1)}$ is actually a tuple which represent the LSTM hidden state value $h^{(t-1)}$ and LSTM cell (memory) value $c^{(t-1)}$.\n",
        "Also when several layers of LSTM exist, each layer will have a specific $s^{(t-1)}$ (such as $s^{(t-1),[1]}$, $s^{(t-1),[2]}$ and $s^{(t-1),[3]}$ for three layers).\n",
        "- also **outputs** the new value of those $s^{(t),[1]}$, $s^{(t),[2]}$ and $s^{(t),[3]}$.\n",
        "\n",
        "$h$ and $c$ are merged into tuples named `hidden` and since we have three LSTM cell we will have the corresponding `hidden1`, `hidden2` and `hidden3`.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epWHM4p6D5n7",
        "outputId": "8127815a-36f9-472a-9153-f24899c8f38c"
      },
      "outputs": [],
      "source": [
        "# --- Create the model\n",
        "\n",
        "if student:\n",
        "    # --- START CODE HERE (03)\n",
        "    class BachModel(nn.Module):\n",
        "\n",
        "        def __init__(self, param):\n",
        "            \"\"\"\n",
        "            \"\"\"\n",
        "            super(BachModel, self).__init__()\n",
        "\n",
        "            self.lstm1 = nn.LSTM(input_size=param.n_x, hidden_size=param.model_n_a, batch_first=True)\n",
        "            self.lstm2 = nn.LSTM(input_size=param.model_n_a, hidden_size=param.model_n_a, batch_first=True)\n",
        "            self.lstm3 = nn.LSTM(input_size=param.model_n_a, hidden_size=param.model_n_a, batch_first=True)\n",
        "            self.dropout = nn.Dropout(param.dropout_rate)\n",
        "            self.fc = nn.Linear(param.model_n_a, param.n_x)\n",
        "\n",
        "        def forward(self, x, hidden1, hidden2, hidden3):\n",
        "            \"\"\"\n",
        "            Parameters\n",
        "            ----------\n",
        "                x (batch_size, T_x, n_x)\n",
        "                    a batch of input sequences\n",
        "                hidden1\n",
        "                    a tuple with hidden state h and cell c, each of size (1, batch_size, n_a), to be used as start for lstm of layer1\n",
        "                hidden2\n",
        "                    same for layer 2\n",
        "                hidden3\n",
        "                    same for layer 3\n",
        "\n",
        "            Returns\n",
        "            -------\n",
        "                logits (batch_size, T_x, n_x)\n",
        "                    predicted logits (before softmax)\n",
        "                hidden1\n",
        "                    new value after processing sequence T_x\n",
        "                hidden2\n",
        "                    new value after processing sequence T_x\n",
        "                hidden2\n",
        "                    new value after processing sequence T_x\n",
        "            \"\"\"\n",
        "            x, hidden1 = self.lstm1(x, hidden1)\n",
        "            x = self.dropout(x)\n",
        "            x, hidden2 = self.lstm2(x, hidden2)\n",
        "            x = self.dropout(x)\n",
        "            x, hidden3 = self.lstm3(x, hidden3)\n",
        "            x = torch.tanh(x)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)\n",
        "            return logits, hidden1, hidden2, hidden3\n",
        "\n",
        "        def init_hidden(self, batch_size, model_n_a):\n",
        "            \"\"\"\n",
        "            \"\"\"\n",
        "            # Initialize hidden state and cell state with zeros\n",
        "            hidden1 = (torch.zeros(1, batch_size, model_n_a).float().to(device),\n",
        "                       torch.zeros(1, batch_size, model_n_a).float().to(device))\n",
        "            hidden2 = (torch.zeros(1, batch_size, model_n_a).float().to(device),\n",
        "                       torch.zeros(1, batch_size, model_n_a).float().to(device))\n",
        "            hidden3 = (torch.zeros(1, batch_size, model_n_a).float().to(device),\n",
        "                       torch.zeros(1, batch_size, model_n_a).float().to(device))\n",
        "            return hidden1, hidden2, hidden3\n",
        "\n",
        "    # --- END CODE HERE\n",
        "\n",
        "\n",
        "# --- fix seed\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# --- check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Instantiate the model and send it to the GPU if available\n",
        "model = BachModel(param).to(device)\n",
        "hidden1, hidden2, hidden3 = model.init_hidden(param.batch_size, param.model_n_a)\n",
        "print(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "zZeog7kiD1Wb",
        "outputId": "5437ea0a-b142-4401-f1a8-e6c115c9d1be"
      },
      "outputs": [],
      "source": [
        "def plot_test(X_train):\n",
        "    \"\"\"\n",
        "    display the obtained probability estimation for a given sequence\n",
        "    \"\"\"\n",
        "    # ----------------------------------------------\n",
        "    input = torch.tensor(X_train[:1,:,:]).float()\n",
        "    hidden1, hidden2, hidden3 = model.init_hidden(input.size(0), param.model_n_a)\n",
        "    output, _, _, _ = model( input.to(device), hidden1, hidden2, hidden3 )\n",
        "    #print(f'input: {input.size()} hidden1: {hidden1[0].size()} output: {output.size()}')\n",
        "\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.subplot(211), plt.imshow(input[0,:,:].T.numpy(), aspect='auto', origin='lower', interpolation='none');\n",
        "    plt.colorbar()\n",
        "    plt.subplot(212), plt.imshow(F.softmax(output[0,:,:]).detach().cpu().T.numpy(), aspect='auto', origin='lower', interpolation='none');\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "plot_test(X_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOxqvs7jV0SI"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, data_loader, criterion, optimizer):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X, y in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        # --- X (m, T_x, n_x)\n",
        "        m = X.size(0)\n",
        "        hidden1, hidden2, hidden3 = model.init_hidden(m, param.model_n_a)\n",
        "        hat_y, _, _, _ = model( X, hidden1, hidden2, hidden3 )\n",
        "        hat_y = hat_y.view(m * param.model_T_x, param.n_x)\n",
        "        y_bol = torch.argmax(y, dim=2)\n",
        "        y_bol = y_bol.view(m * param.model_T_x)\n",
        "\n",
        "        loss = criterion(hat_y, y_bol)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss/len(data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhWTNfIbFDmf"
      },
      "outputs": [],
      "source": [
        "def train(model, X_train, Y_train, epochs=param.n_epoch, batch_size=param.batch_size):\n",
        "\n",
        "    \"\"\"\n",
        "    train the model\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model:\n",
        "        ...\n",
        "\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Move the model to the device (GPU or CPU)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # ---  Convert numpy.arrays to torch.tensor\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "    Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
        "\n",
        "    # ---  Create Datasets for train data\n",
        "    train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "\n",
        "    # --- Create Dataloader for train data\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # ---  Loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(),lr=0.01)\n",
        "\n",
        "    # ---  Training loop\n",
        "    # for epoch in range(epochs):\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
        "        if epoch%100==0:\n",
        "            print(f\"Epoch {epoch + 1}, Loss: {train_loss }\")\n",
        "            plot_test(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PMf9aKp4vMCD",
        "outputId": "36c92f6a-b8f3-49d0-eeea-c809c2f68f91"
      },
      "outputs": [],
      "source": [
        "train(model, X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM6g1YR3gtcO"
      },
      "source": [
        "# Generating a new sequence by sampling the language model\n",
        "\n",
        "<img src=\"https://docs.google.com/uc?export=download&id=129zZNNKNq1oXG21kLKDDUvGY_po6eS6Q\" width=700>\n",
        "\n",
        "To generate a new sequence using the trained language model, we will use an **auto-regressive** method: we generate time-step $t$ based on the previously generated time-steps $0$ to $t-1$.\n",
        "\n",
        "For the first step\n",
        "- $\\hat{y}^{(1)} = p(x^{(2)} | \\color{red}{x^{(1)}} ; \\color{blue}{s^{(0)}=[-]})\\\\x^{(2)} \\sim \\hat{y}^{(1)}$\n",
        "\n",
        "For the second step\n",
        "- $\\hat{y}^{(2)} = p(x^{(3)} | \\color{red}{x^{(2)}} ; \\color{blue}{s^{(1)}=[x^{(1)}]})\\\\x^{(3)} \\sim \\hat{y}^{(2)}$\n",
        "\n",
        "The third step\n",
        "- $\\hat{y}^{(3)} = p(x^{(4)} |\\color{red}{ x^{(3)}} ; \\color{blue}{s^{(2)}=[x^{(1)} x^{(2)}]})\\\\x^{(4)} \\sim \\hat{y}^{(3)}$\n",
        "\n",
        "For the $t$ step:\n",
        "- $\\hat{y}^{(t)} = p(x^{(t+1)} | \\color{red}{{x^{(t)}}} ; \\color{blue}{s^{(t-1)}=[x^{(1)} ... x^{(t-1)}]})\\\\x^{(t+1)} \\sim \\hat{y}^{(t)}$\n",
        "\n",
        "In the above \"$\\sim$\" denotes \"sampled from the distribution\"\n",
        "\n",
        "At time step $t$, the model gets\n",
        "- as input (red part): the previous generated time step $x^{(t)} \\sim \\hat{y}^{(t-1)}$\n",
        "- as previous RNN value (blue part) $s^{(t-1)}$. The previous RNN value sums up the times $x^{(1)} ... x^{(t-1)}$.\n",
        "In the case of LSTM, $s^{(t-1)}$ is actually a tuple which represent the LSTM hidden state value $h^{(t-1)}$ and LSTM cell (memory) value $c^{(t-1)}$.\n",
        "Also when several layers of LSTM exist, each layer will have a specific $s^{(t-1)}$ (such as $s^{(t-1),[1]}$, $s^{(t-1),[2]}$ and $s^{(t-1),[3]}$ for three layers).\n",
        "\n",
        "\n",
        "### Initialisation (`t=1`)\n",
        "\n",
        "For the start, we set $x^{(1)}$ to a randomly choosen note among the `param.n_x` possible notes. For this you can\n",
        "- either sample from an uniform distribution among the notes -> `get_prior_uniform`\n",
        "- or sample from a prior note distribution (the prior can be obtained by counting the number of occurences of each notes in the training set) -> `get_prior_data_distribution`\n",
        "\n",
        "To sample from a distribution you can use `np.random.multinomial`.\n",
        "\n",
        "We then create an input `x` that will be used by our `model`. Our model requires data of shape `(m, T_x, n_x)`. In our case\n",
        "- `m=1` since we have only one sequence,\n",
        "- `T_x=1` since we only consider one time at a given time (auto-regressive)\n",
        "- `n_x` is the number of notes.\n",
        "\n",
        "We set the input data `x[0,0,:]` to the one-hot-encoding of our random note $x^{(1)}$.\n",
        "\n",
        "For the start, we do not have previous RNN values, we therefore set $s^{(0)}$ to 0.\n",
        "This is done using `model.init_hidden`. We denote those `hidden1, hidden2, hidden3`.\n",
        "\n",
        "We then feed our model with data `x[0,0,:]` and `hidden1, hidden2, hidden3`.\n",
        "\n",
        "### Loop\n",
        "\n",
        "At time $t$, our model predict $\\hat{y}^{(t)}=p(x^{(t+1)} | \\color{red}{{x^{(t)}}} ; \\color{blue}{s^{(t-1)}=[x^{(1)} ... x^{(t-1)}]})$.\n",
        "\n",
        "The inputs of the model are\n",
        "- the one-hot-encoding of the previously chosen note $x^{(t)} \\sim \\hat{y}^{(t-1)}$; it is stored in `x[0,0,:]`\n",
        "- the previous RNN value $s^{(t-1)}$; it is stored in `hidden1, hidden2, hidden3`\n",
        "\n",
        "The outputs of `model.forward()` are\n",
        "- the `logits` $\\in [-\\inf,\\inf]$ of shape `(1, 1, n_x)` of each note (remember that the `softmax` is not part of our model; the softmax is included in the Loss, not in the model).\n",
        "- the new RNN values $s^{(t)}$\n",
        "\n",
        "To get $\\hat{y}^{(t)}$ from the logits at time `t`, we can  \n",
        "- (a) either convert this logit vector to a probablity using standard softmax -> `get_softmax`\n",
        "- (b) or convert this logit vector to a probablity using a softmax **with temperature** -> `get_softmax_temperature`.\n",
        "To apply a temperature $T$ parameter to a discrete probability $\\{p_c\\}_{c \\in \\{1,...,K\\}}$, you can use\n",
        "$p'_c = \\frac{e^{\\log(p_c)/T}}{\\sum_{k=1}^K e^{\\log(p_k)/T}}$ where $K$ is the number of classes.\n",
        "\n",
        "To get $x^{(t+1)}$ from the resulting probablity $\\hat{y}^{(t)}$ we can then\n",
        "- (a) either select the largest probability -> `np.argmax`\n",
        "- (b) or consider the probability as a multinomial distribution and sample from it -> `np.random.multinomial`.\n",
        "\n",
        "We append the chosen note $x^{(t+1)}$ to the list of chosen notes ->  `note_l.append()`.\n",
        "We append the used probablity $\\hat{y}^{(t)}$ to the list of probablities -> `prediction_l.append()`.\n",
        "\n",
        "### Stop criteria\n",
        "\n",
        "We repeat the process until we generate the required amount of notes `param.model_T_generate`.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxcjs5SmumG9"
      },
      "outputs": [],
      "source": [
        "# --- np: numpy\n",
        "# --- to: pytorch\n",
        "\n",
        "def get_prior_uniform(n_x):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    prior_np_v = np.ones(n_x)/n_x\n",
        "    return prior_np_v\n",
        "\n",
        "def get_prior_data_distribution(X_train_np, n_x):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    sum_np_v = np.zeros(n_x)\n",
        "    for X_ohe_np in X_train_np:\n",
        "        sum_np_v += np.sum(X_ohe_np, axis=0)\n",
        "    prior_np_v = sum_np_v/np.sum(sum_np_v)\n",
        "    return prior_np_v\n",
        "\n",
        "def get_softmax(hat_logit_to):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    proba_np_v = F.softmax( hat_logit_to.double() ).numpy()\n",
        "    return proba_np_v\n",
        "\n",
        "def get_softmax_temperature(hat_logit_to, temperature):\n",
        "    \"\"\"\n",
        "    compute a softmax with temperature\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    logits_v: n_x\n",
        "        input un-normalized logits \\in [-inf, inf]\n",
        "    temperature: scalar float\n",
        "        temperature parameters to apply to proba_v,\n",
        "        >1 leads to more flatten probability,\n",
        "        <1 leads to more peaky probability\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    proba_v: np.array(n_x)\n",
        "        probability scaled by temperature\n",
        "    \"\"\"\n",
        "    if student:\n",
        "        ...\n",
        "\n",
        "    return proba_np_v\n",
        "\n",
        "def choose_max(proba_np_v):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    index_pred = np.argmax(proba_np_v)\n",
        "    return index_pred\n",
        "\n",
        "def choose_max_multinormial(proba_np_v):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    index_pred = np.argmax(np.random.multinomial(1, proba_np_v))\n",
        "    return index_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_ADCs7uFW8m"
      },
      "outputs": [],
      "source": [
        "def F_sample_new_sequence(model):\n",
        "    \"\"\"\n",
        "    sample the trained language model to generate new data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model:\n",
        "        trained language model\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    note_l: list of int\n",
        "        list of generated notes (list of their index)\n",
        "    prediction_l: list of np.array(n_x)\n",
        "        list of prediction probabilies over time t (each entry of the list is one of the y[0,t,:])\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(0);\n",
        "    note_l = []\n",
        "    prediction_l = []\n",
        "\n",
        "    if student:\n",
        "        # --- START CODE HERE (05)\n",
        "        ...\n",
        "        # --- END CODE HERE\n",
        "\n",
        "    return note_l, prediction_l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stQscvNOg0xd"
      },
      "source": [
        "### Display the generated sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "c9IOPPiuLuHE",
        "outputId": "7eebd377-fbe2-4e0e-9a03-ae3fda7f6539"
      },
      "outputs": [],
      "source": [
        "note_l, prediction_l = F_sample_new_sequence(model)\n",
        "\n",
        "print(note_l)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(np.asarray(prediction_l).T, aspect='auto', origin='lower')\n",
        "plt.plot(note_l, 'ro')\n",
        "plt.set_cmap('gray_r')\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwM6osfDg5E0"
      },
      "source": [
        "### Create a MIDI file and an audio file which correspond to the generated sequence\n",
        "\n",
        "Once the new sequence has been generated (```note_l```) we transform it to a new MIDI file and perform (a very cheap) rendering of it in an audio file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cpTszOFID51"
      },
      "outputs": [],
      "source": [
        "new_midi_data = pretty_midi.PrettyMIDI()\n",
        "cello_program = pretty_midi.instrument_name_to_program('Cello')\n",
        "cello = pretty_midi.Instrument(program=cello_program)\n",
        "time = 0\n",
        "step = 0.3\n",
        "for note_number in note_l:\n",
        "    myNote = pretty_midi.Note(velocity=100, pitch=note_number, start=time, end=time+step)\n",
        "    cello.notes.append(myNote)\n",
        "    time += step\n",
        "new_midi_data.instruments.append(cello)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "yOXBXxa3IGKW",
        "outputId": "4aadc3b0-f679-471f-d23f-2f94a56ee456"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "audio_data = new_midi_data.synthesize()\n",
        "IPython.display.Audio(audio_data, rate=44100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw-A1FW4V0SJ"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "To evaluate the work, you should rate the code for\n",
        "- 1) MIDI conversion to one-hot-encoding: `F_convert_midi_2_list` (01)\n",
        "- 2) Data conversion for the training of language model (02) `F_convert_list_2_data`\n",
        "- 3) Training the language model (03)\n",
        "- 4) Generating a new sequence from sampling the language model `F_sample_new_sequence` (04)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKUxLAwMV0SK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
