{"cells":[{"cell_type":"markdown","metadata":{"id":"kaht-FPA1Jvq"},"source":["# Introduction\n","\n","## Lab2: Train a Convolutional Neural Network (CNN).\n","\n","In this Lab session we will learn how to train a CNN from scratch for classifying MNIST digits."]},{"cell_type":"code","execution_count":64,"metadata":{"id":"UvxtTYHlVfRK"},"outputs":[],"source":["# import necessary libraries\n","import torch\n","import torchvision\n","from torchvision import transforms as T\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"HYCvhGxKWyN7"},"source":["### Define LeNet\n","\n","![network architecture](https://www.researchgate.net/profile/Lucijano-Berus/publication/329891470/figure/fig1/AS:707347647307776@1545656229128/Architecture-of-LeNet-5-a-Convolutional-Neural-Network-for-digits-digits-recognition-An.ppm)\n","\n","Here we are going to define our first CNN which is **LeNet** in this case. This architecture has been introduced and is detailed in [this article](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf). To construct a LeNet we will be using some convolutional layers followed by some fully-connected layers. The convolutional layers can be simply defined using `torch.nn.Conv2d` module of `torch.nn` package. Details can be found [here](https://pytorch.org/docs/stable/nn.html#conv2d). Moreover, we will use pooling operation to reduce the size of convolutional feature maps. For this case we are going to use `torch.nn.functional.max_pool2d`. Details about maxpooling can be found [here](https://pytorch.org/docs/stable/nn.html#max-pool2d)\n","\n","Differently from our previous Lab, we will use a Rectified Linear Units (ReLU) as activation function with the help of `torch.nn.functional.relu`, replacing `torch.nn.Sigmoid`. Details about ReLU can be found [here](https://pytorch.org/docs/stable/nn.html#id26)."]},{"cell_type":"code","execution_count":65,"metadata":{"id":"dMC_LDYdWkI7"},"outputs":[],"source":["class LeNet(torch.nn.Module):\n","  def __init__(self):\n","    super(LeNet, self).__init__()\n","\n","    # input channel = 1, output channels = 6, kernel size = 5\n","    # input image size = (32, 32), image output size = (28, 28)\n","    self.conv1 = torch.nn.Conv2d(1, 6, kernel_size=5)\n","    self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n","\n","    # input channel = 6, output channels = 16, kernel size = 5\n","    # input image size = (14, 14), output image size = (10, 10)\n","    self.conv2 = torch.nn.Conv2d(6, 16, kernel_size=5)\n","    self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n","\n","    # input dim = 5*5*16 ( H x W x C), output dim = 120\n","    self.fc1 = torch.nn.Linear(5*5*16, 120)\n","    self.active1 = torch.nn.ReLU()\n","\n","    # input dim = 120, output dim = 84\n","    self.fc2 = torch.nn.Linear(120, 84)\n","    self.active2 = torch.nn.ReLU()\n","\n","    # input dim = 84, output dim = 10\n","    self.fc3 = torch.nn.Linear(84, 10)\n","    self.active3 = torch.nn.LogSoftmax(dim=1)\n","\n","  def forward(self, x):\n","    # zero padding = 2, change input image size = (32, 32)\n","    x = F.pad(x, (2, 2, 2, 2))\n","\n","    x = self.conv1(x)\n","    # Max Pooling with kernel size = 2\n","    # output size = (14, 14)\n","    x = self.maxpool1(x)\n","\n","    x = self.conv2(x)\n","    # Max Pooling with kernel size = 2\n","    # output size = (5, 5)\n","    x = self.maxpool2(x)\n","\n","    # flatten the feature maps into a long vector\n","    x = x.view(x.shape[0], -1)\n","\n","    x = self.fc1(x)\n","    x = self.active1(x)\n","\n","    x = self.fc2(x)\n","    x = self.active2(x)\n","\n","    x = self.fc3(x)\n","    x = self.active3(x)\n","\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"gChf6TvWonrV"},"source":["### Define cost function"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"6j5UrBH3oek8"},"outputs":[],"source":["def get_cost_function():\n","  cost_function = torch.nn.CrossEntropyLoss()\n","  return cost_function"]},{"cell_type":"markdown","metadata":{"id":"U2TjXeVdorV9"},"source":["### Define the optimizer\n","\n","We will use SGD with learning rate-lr, weight_decay=wd and  momentum=momentum"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"hBZN-WPboulR"},"outputs":[],"source":["def get_optimizer(net, lr, wd, momentum):\n","  optimizer =  torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n","  return optimizer"]},{"cell_type":"markdown","metadata":{"id":"wTkfrV64oxIL"},"source":["### Train and test functions"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"t-sE5vFio0lf"},"outputs":[],"source":["def test(net, data_loader, cost_function, device='cuda:0'):\n","  samples = 0.\n","  cumulative_loss = 0.\n","  cumulative_accuracy = 0.\n","\n","  net.eval() # Strictly needed if network contains layers which has different behaviours between train and test\n","  with torch.no_grad():\n","    for batch_idx, (inputs, targets) in enumerate(data_loader):\n","      # Load data into GPU\n","      inputs = inputs.to(device)\n","      targets = targets.to(device)\n","\n","      # Forward pass\n","      outputs = net(inputs)\n","\n","      # Apply the loss\n","      loss = cost_function(outputs, targets)\n","\n","      # Better print something\n","      samples+=inputs.shape[0]\n","      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n","      _, predicted = outputs.max(1)\n","      cumulative_accuracy += predicted.eq(targets).sum().item()\n","\n","  return cumulative_loss/samples, cumulative_accuracy/samples*100\n","\n","\n","def train(net,data_loader,optimizer,cost_function, device='cuda:0'):\n","  samples = 0.\n","  cumulative_loss = 0.\n","  cumulative_accuracy = 0.\n","\n","\n","  net.train() # Strictly needed if network contains layers which has different behaviours between train and test\n","  for batch_idx, (inputs, targets) in enumerate(data_loader):\n","    # Load data into GPU\n","    inputs = inputs.to(device)\n","    targets = targets.to(device)\n","\n","    # Forward pass\n","    outputs = net(inputs)\n","\n","    # Apply the loss\n","    loss = cost_function(outputs,targets)\n","\n","    # Reset the optimizer\n","\n","    # Backward pass\n","    loss.backward()\n","\n","    # Update parameters\n","    optimizer.step()\n","\n","    optimizer.zero_grad()\n","\n","    # Better print something, no?\n","    samples+=inputs.shape[0]\n","    cumulative_loss += loss.item()\n","    _, predicted = outputs.max(1)\n","    cumulative_accuracy += predicted.eq(targets).sum().item()\n","\n","  return cumulative_loss/samples, cumulative_accuracy/samples*100"]},{"cell_type":"markdown","metadata":{"id":"T6IT0Lsgo8AM"},"source":["### Define the function that fetches a data loader that is then used during iterative training.\n","\n","We will learn a new thing in this function as how to Normalize the inputs given to the network.\n","\n","***Why Normalization is needed***?\n","\n","To have nice and stable training of the network it is recommended to normalize the network inputs between \\[-1, 1\\].\n","\n","***How it can be done***?\n","\n","This can be simply done using `torchvision.transforms.Normalize()` transform. Details can be found [here](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize)."]},{"cell_type":"code","execution_count":69,"metadata":{"id":"qDxpo6uVo_8k"},"outputs":[],"source":["def get_data(batch_size, test_batch_size=256):\n","\n","  # Prepare data transformations and then combine them sequentially\n","  transform = list()\n","  transform.append(T.ToTensor())                            # converts Numpy to Pytorch Tensor\n","  transform.append(T.Normalize(mean=[0.5], std=[0.5]))      # Normalizes the Tensors between [-1, 1]\n","  transform = T.Compose(transform)                          # Composes the above transformations into one.\n","\n","  # Load data\n","  full_training_data = torchvision.datasets.MNIST('./data', train=True, transform=transform, download=True)\n","  test_data = torchvision.datasets.MNIST('./data', train=False, transform=transform, download=True)\n","\n","\n","  # Create train and validation splits\n","  num_samples = len(full_training_data)\n","  training_samples = int(num_samples*0.5+1)\n","  validation_samples = num_samples - training_samples\n","\n","  training_data, validation_data = torch.utils.data.random_split(full_training_data, [training_samples, validation_samples])\n","\n","  # Initialize dataloaders\n","  train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True)\n","  val_loader = torch.utils.data.DataLoader(validation_data, test_batch_size, shuffle=False)\n","  test_loader = torch.utils.data.DataLoader(test_data, test_batch_size, shuffle=False)\n","\n","  return train_loader, val_loader, test_loader"]},{"cell_type":"markdown","metadata":{"id":"OHcB8f0AsY4n"},"source":["### Wrapping everything up\n","\n","Finally, we need a main function which initializes everything + the needed hyperparameters and loops over multiple epochs (printing the results)."]},{"cell_type":"code","execution_count":70,"metadata":{"id":"ip_R-hruse0Q"},"outputs":[],"source":["'''\n","Input arguments\n","  batch_size: Size of a mini-batch\n","  device: GPU where you want to train your network\n","  weight_decay: Weight decay co-efficient for regularization of weights\n","  momentum: Momentum for SGD optimizer\n","  epochs: Number of epochs for training the network\n","'''\n","\n","def main(batch_size=128,\n","         device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu'),\n","         learning_rate=0.01,\n","         weight_decay=0.000001,\n","         momentum=0.9,\n","         epochs=50):\n","\n","  train_loader, val_loader, test_loader = get_data(batch_size)\n","\n","  net = LeNet().to(device)\n","\n","  optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n","\n","  cost_function = get_cost_function()\n","\n","  print('Before training:')\n","  train_loss, train_accuracy = test(net, train_loader, cost_function, device)\n","  val_loss, val_accuracy = test(net, val_loader, cost_function, device)\n","  test_loss, test_accuracy = test(net, test_loader, cost_function, device)\n","\n","  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n","  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n","  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n","  print('-----------------------------------------------------')\n","\n","  for e in range(epochs):\n","    train_loss, train_accuracy = train(net, train_loader, optimizer, cost_function, device)\n","    val_loss, val_accuracy = test(net, val_loader, cost_function, device)\n","    print('Epoch: {:d}'.format(e+1))\n","    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n","    print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n","    print('-----------------------------------------------------')\n","\n","  print('After training:')\n","  train_loss, train_accuracy = test(net, train_loader, cost_function, device)\n","  val_loss, val_accuracy = test(net, val_loader, cost_function, device)\n","  test_loss, test_accuracy = test(net, test_loader, cost_function, device)\n","\n","  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n","  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n","  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n","  print('-----------------------------------------------------')"]},{"cell_type":"markdown","metadata":{"id":"ltdCMiB3t18h"},"source":["Lets train!"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"6d-z20H4tziL"},"outputs":[{"name":"stdout","output_type":"stream","text":["Before training:\n","\t Training loss 0.01807, Training accuracy 9.66\n","\t Validation loss 0.00908, Validation accuracy 9.49\n","\t Test loss 0.00923, Test accuracy 9.48\n","-----------------------------------------------------\n","Epoch: 1\n","\t Training loss 0.00723, Training accuracy 69.78\n","\t Validation loss 0.00078, Validation accuracy 93.67\n","-----------------------------------------------------\n","Epoch: 2\n","\t Training loss 0.00111, Training accuracy 95.51\n","\t Validation loss 0.00046, Validation accuracy 96.24\n","-----------------------------------------------------\n","Epoch: 3\n","\t Training loss 0.00072, Training accuracy 97.08\n","\t Validation loss 0.00036, Validation accuracy 97.25\n","-----------------------------------------------------\n","Epoch: 4\n","\t Training loss 0.00057, Training accuracy 97.64\n","\t Validation loss 0.00029, Validation accuracy 97.67\n","-----------------------------------------------------\n","Epoch: 5\n","\t Training loss 0.00042, Training accuracy 98.28\n","\t Validation loss 0.00028, Validation accuracy 97.69\n","-----------------------------------------------------\n","Epoch: 6\n","\t Training loss 0.00034, Training accuracy 98.64\n","\t Validation loss 0.00025, Validation accuracy 98.09\n","-----------------------------------------------------\n","Epoch: 7\n","\t Training loss 0.00030, Training accuracy 98.79\n","\t Validation loss 0.00024, Validation accuracy 98.14\n","-----------------------------------------------------\n","Epoch: 8\n","\t Training loss 0.00024, Training accuracy 98.97\n","\t Validation loss 0.00026, Validation accuracy 97.99\n","-----------------------------------------------------\n","Epoch: 9\n","\t Training loss 0.00019, Training accuracy 99.21\n","\t Validation loss 0.00023, Validation accuracy 98.34\n","-----------------------------------------------------\n","Epoch: 10\n","\t Training loss 0.00018, Training accuracy 99.29\n","\t Validation loss 0.00022, Validation accuracy 98.41\n","-----------------------------------------------------\n","Epoch: 11\n","\t Training loss 0.00014, Training accuracy 99.42\n","\t Validation loss 0.00022, Validation accuracy 98.41\n","-----------------------------------------------------\n","Epoch: 12\n","\t Training loss 0.00013, Training accuracy 99.47\n","\t Validation loss 0.00022, Validation accuracy 98.47\n","-----------------------------------------------------\n","Epoch: 13\n","\t Training loss 0.00008, Training accuracy 99.73\n","\t Validation loss 0.00023, Validation accuracy 98.51\n","-----------------------------------------------------\n","Epoch: 14\n","\t Training loss 0.00009, Training accuracy 99.66\n","\t Validation loss 0.00025, Validation accuracy 98.36\n","-----------------------------------------------------\n","Epoch: 15\n","\t Training loss 0.00008, Training accuracy 99.65\n","\t Validation loss 0.00026, Validation accuracy 98.35\n","-----------------------------------------------------\n","Epoch: 16\n","\t Training loss 0.00007, Training accuracy 99.76\n","\t Validation loss 0.00025, Validation accuracy 98.40\n","-----------------------------------------------------\n","Epoch: 17\n","\t Training loss 0.00006, Training accuracy 99.75\n","\t Validation loss 0.00025, Validation accuracy 98.38\n","-----------------------------------------------------\n","Epoch: 18\n","\t Training loss 0.00005, Training accuracy 99.80\n","\t Validation loss 0.00024, Validation accuracy 98.51\n","-----------------------------------------------------\n","Epoch: 19\n","\t Training loss 0.00003, Training accuracy 99.93\n","\t Validation loss 0.00027, Validation accuracy 98.48\n","-----------------------------------------------------\n","Epoch: 20\n","\t Training loss 0.00003, Training accuracy 99.89\n","\t Validation loss 0.00027, Validation accuracy 98.50\n","-----------------------------------------------------\n","Epoch: 21\n","\t Training loss 0.00002, Training accuracy 99.92\n","\t Validation loss 0.00025, Validation accuracy 98.56\n","-----------------------------------------------------\n","Epoch: 22\n","\t Training loss 0.00002, Training accuracy 99.95\n","\t Validation loss 0.00024, Validation accuracy 98.66\n","-----------------------------------------------------\n","Epoch: 23\n","\t Training loss 0.00001, Training accuracy 99.99\n","\t Validation loss 0.00025, Validation accuracy 98.60\n","-----------------------------------------------------\n","Epoch: 24\n","\t Training loss 0.00001, Training accuracy 99.99\n","\t Validation loss 0.00025, Validation accuracy 98.64\n","-----------------------------------------------------\n","Epoch: 25\n","\t Training loss 0.00000, Training accuracy 99.99\n","\t Validation loss 0.00025, Validation accuracy 98.65\n","-----------------------------------------------------\n","Epoch: 26\n","\t Training loss 0.00001, Training accuracy 99.99\n","\t Validation loss 0.00026, Validation accuracy 98.64\n","-----------------------------------------------------\n","Epoch: 27\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00026, Validation accuracy 98.66\n","-----------------------------------------------------\n","Epoch: 28\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00026, Validation accuracy 98.67\n","-----------------------------------------------------\n","Epoch: 29\n","\t Training loss 0.00000, Training accuracy 99.99\n","\t Validation loss 0.00026, Validation accuracy 98.68\n","-----------------------------------------------------\n","Epoch: 30\n","\t Training loss 0.00000, Training accuracy 99.98\n","\t Validation loss 0.00027, Validation accuracy 98.66\n","-----------------------------------------------------\n","Epoch: 31\n","\t Training loss 0.00000, Training accuracy 99.99\n","\t Validation loss 0.00027, Validation accuracy 98.66\n","-----------------------------------------------------\n","Epoch: 32\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00027, Validation accuracy 98.65\n","-----------------------------------------------------\n","Epoch: 33\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00027, Validation accuracy 98.69\n","-----------------------------------------------------\n","Epoch: 34\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00027, Validation accuracy 98.70\n","-----------------------------------------------------\n","Epoch: 35\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00027, Validation accuracy 98.68\n","-----------------------------------------------------\n","Epoch: 36\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00027, Validation accuracy 98.68\n","-----------------------------------------------------\n","Epoch: 37\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00028, Validation accuracy 98.68\n","-----------------------------------------------------\n","Epoch: 38\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00028, Validation accuracy 98.69\n","-----------------------------------------------------\n","Epoch: 39\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00028, Validation accuracy 98.68\n","-----------------------------------------------------\n","Epoch: 40\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00028, Validation accuracy 98.69\n","-----------------------------------------------------\n","Epoch: 41\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00028, Validation accuracy 98.69\n","-----------------------------------------------------\n","Epoch: 42\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00028, Validation accuracy 98.68\n","-----------------------------------------------------\n","Epoch: 43\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00028, Validation accuracy 98.69\n","-----------------------------------------------------\n","Epoch: 44\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00029, Validation accuracy 98.69\n","-----------------------------------------------------\n","Epoch: 45\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00029, Validation accuracy 98.69\n","-----------------------------------------------------\n","Epoch: 46\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00029, Validation accuracy 98.68\n","-----------------------------------------------------\n","Epoch: 47\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00029, Validation accuracy 98.69\n","-----------------------------------------------------\n","Epoch: 48\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00029, Validation accuracy 98.69\n","-----------------------------------------------------\n","Epoch: 49\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00029, Validation accuracy 98.68\n","-----------------------------------------------------\n","Epoch: 50\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00029, Validation accuracy 98.70\n","-----------------------------------------------------\n","After training:\n","\t Training loss 0.00000, Training accuracy 100.00\n","\t Validation loss 0.00029, Validation accuracy 98.70\n","\t Test loss 0.00024, Test accuracy 98.79\n","-----------------------------------------------------\n"]}],"source":["main()"]},{"cell_type":"markdown","metadata":{"id":"NQBDT48CKMVC"},"source":["Using the proper metric from sklearn, check which character is most frequently confused with which: can you explain why ?\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sm5b4MV1KzQ7"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZOvixkfeMHrD"},"source":["The LeNet5 architecture can also be implemented using the sequential API ([see documentation ](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)). Reimplement it with this API."]},{"cell_type":"markdown","metadata":{"id":"7i3-pC5xAyu5"},"source":["##Experiments\n","\n","\n","* Implement adaptive early stopping: if the validation loss did not decrease for K consecutive epochs, stop training.\n","* Change dataset in order to evaluate the LeNet5 network on cifar10 dataset. You can have a look at the pytorch to easily access the cifar10 dataset.\n","* Try to improve performance with:\n","   *   data-augmentation\n","   *   dropout\n","* Implement the resnet18 architecture using the Resnet18 class from pytorch.\n","\n","\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1o6orxhxIapGZWt5FD4v7T8BRwdcSCEW4","timestamp":1684744697778},{"file_id":"1dpY2_Um7w8Qqx5c0e_vD2qaXXFW2LE3j","timestamp":1684248464934}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}
