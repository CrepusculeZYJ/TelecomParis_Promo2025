{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change here using YOUR own first and last names\n",
    "fn1 = \"Jiale\"\n",
    "ln1 = \"KANG\"\n",
    "filename = \"_\".join(map(lambda s: s.strip().lower(),\n",
    "[\"SD-TSIA204_lab2\", ln1, fn1])) + \".ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my MSE: 0.524320986184607 Sklearn MSE: 0.524320986184607\n",
      "my R2 : 0.6062326851998052 Sklearn R2 : 0.6062326851998052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error as sklearn_mse\n",
    "from sklearn.metrics import r2_score as sklearn_r2\n",
    "import numpy as np\n",
    "\n",
    "data_set = fetch_california_housing()\n",
    "X = data_set.data\n",
    "y = data_set.target\n",
    "\n",
    "X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "# theta = (X^T X)^(-1) X^T y\n",
    "theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "def compute_MSE(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def compute_R2(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "y_pred = X.dot(theta)\n",
    "\n",
    "my_mse = compute_MSE(y, y_pred)\n",
    "my_r2 = compute_R2(y, y_pred)\n",
    "\n",
    "sklearn_mse = sklearn_mse(y, y_pred)\n",
    "sklearn_r2 = sklearn_r2(y, y_pred)\n",
    "\n",
    "print(\"my MSE:\", my_mse, \"Sklearn MSE:\", sklearn_mse)\n",
    "print(\"my R2 :\", my_r2, \"Sklearn R2 :\", sklearn_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient 0: 99% CI = (-38.63874945118044, -35.24509096143688)\n",
      "Coefficient 1: 99% CI = (0.42588540249626045, 0.4475011837773342)\n",
      "Coefficient 2: 99% CI = (0.008286488997305977, 0.010585067069474924)\n",
      "Coefficient 3: 99% CI = (-0.12247846827219933, -0.09216561451536173)\n",
      "Coefficient 4: 99% CI = (0.5726106847258521, 0.7175207023358563)\n",
      "Coefficient 5: 99% CI = (-1.6206846472410517e-05, 8.25406763075563e-06)\n",
      "Coefficient 6: 99% CI = (-0.0050417663608660936, -0.0025313189491208005)\n",
      "Coefficient 7: 99% CI = (-0.43984823431362086, -0.4027805207223839)\n",
      "Coefficient 8: 99% CI = (-0.4539129628944105, -0.4151145464347442)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Compute the residuals and their variance\n",
    "residuals = y - y_pred\n",
    "sigma_squared = np.mean(residuals ** 2)\n",
    "\n",
    "# Compute the standard errors\n",
    "XtX_inv = np.linalg.inv(X.T.dot(X))\n",
    "standard_errors = np.sqrt(np.diag(sigma_squared * XtX_inv))\n",
    "\n",
    "z = stats.norm.ppf(0.995)\n",
    "confidence_intervals = [(theta[i] - z * standard_errors[i], theta[i] + z * standard_errors[i]) for i in range(len(theta))]\n",
    "\n",
    "for i, ci in enumerate(confidence_intervals):\n",
    "    print(f\"Coefficient {i}: 99% CI = {ci}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv(\"data.csv\", sep=\",\", header=None)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(210, axis=1), data[210], test_size=0.25, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def fit_OLS(X,y):\n",
    "    theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return theta\n",
    "\n",
    "# fit OLS using LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr_theta = np.r_[lr.intercept_, lr.coef_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature    167\n",
       "p_value    0.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "def choose_single_variable(X,y):\n",
    "    results = pd.DataFrame(columns=['feature', 'p_value'])\n",
    "    \n",
    "    # Loop over all columns in X\n",
    "    for column in range(X.shape[1]):\n",
    "        X_column = X[:,column].reshape(-1,1)\n",
    "        # Fit model\n",
    "        model = LinearRegression().fit(X_column, y)\n",
    "        # Calculate t-statistic\n",
    "        t_stat = model.coef_ / (np.sqrt(compute_MSE(y, model.predict(X_column)) / ((X_column.var()) * (len(y) - 2))))\n",
    "        # Calculate p-value\n",
    "        p_value = 2 * (1 - t.cdf(np.abs(t_stat), df=len(y)-2))\n",
    "        # Append results use pandas.concat\n",
    "        results = pd.concat([results, pd.DataFrame({'feature': [column], 'p_value': p_value})])\n",
    "    \n",
    "    # Return the feature with the smallest p-value\n",
    "    return results.sort_values('p_value').iloc[0]\n",
    "\n",
    "choose_single_variable(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [47], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m included_features\n\u001b[0;32m---> 14\u001b[0m forward_selection(X_train_scaled, y_train)\n",
      "Cell \u001b[0;32mIn [47], line 5\u001b[0m, in \u001b[0;36mforward_selection\u001b[0;34m(X, y, significance_level)\u001b[0m\n\u001b[1;32m      3\u001b[0m included_features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     remaining_features \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241m.\u001b[39mdifference(included_features)\n\u001b[1;32m      6\u001b[0m     new_feature \u001b[38;5;241m=\u001b[39m choose_single_variable(X[remaining_features], y)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_feature[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m significance_level:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "def forward_selection(X, y, significance_level=0.05):\n",
    "\n",
    "    included_features = []\n",
    "    while True:\n",
    "        remaining_features = X.columns.difference(included_features)\n",
    "        new_feature = choose_single_variable(X[remaining_features], y)\n",
    "        if new_feature['p_value'] < significance_level:\n",
    "            included_features.append(new_feature['feature'])\n",
    "            print(f\"Feature {new_feature['feature']} with p-value {new_feature['p_value']} was included.\")\n",
    "        else:\n",
    "            break\n",
    "    return included_features\n",
    "\n",
    "forward_selection(X_train_scaled, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
